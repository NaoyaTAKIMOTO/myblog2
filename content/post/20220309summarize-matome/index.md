---
title: "日本語要約の手法・サービスのまとめ"
description: ""
date: "2022-03-09T14:51:58+09:00"
thumbnail: ""
tags: [要約,BART,技術系,自然言語処理,技術,分散表現,文生成]
---
- 日本語文章の自動要約について調べたのでまとめておく
- 原文から一部を選択的に抜粋する抽出型と機械翻訳のように対応する要約文を生成する生成型がある
- またウェブで公開されている要約サービスもある


## 生成型要約
### モデル
- DNN　言語モデル
  - BERTの文脈から派生した要約手法が多い
  - BART
    - BERTから文の要約に特化して派生したもの
    - [BART(文章要約モデル)]({{<ref "post/20210119huggingface/index.md">}})は日本語に対応していない
  - T5
    - 学習をすべて自然言語で設定して行うことで複数のタスクへと柔軟に対応する、というコンセプトのモデル
    - [T5がhugging face で公開]({{<ref "post/20210701T5/index.md">}})されたモデルをファインチューニングして使うことが割と手軽にできた
    - 要約だけでなく単語の分散表現を得ることにも使える
- 整数計画問題
  - ソルバーで厳密に解くことができる
    - 無償のソルバーはpythonだと[pulp](https://coin-or.github.io/pulp/index.html), [Python-MIP](https://www.python-mip.com/)が選択肢になる
    - 式を記述する際の挙動の軽さから私はPython-MIPを勧める
  - 制約条件として文の数、文字数を指定できる
  - 計算時間が短いというわけではない
    - 定式化の問題か？
  - 各モデル
    - 文全体が一つのトピックを扱っていると仮定して、その代表的な文を拾ってくるイメージ
    - McDonaldモデル
    - 最大被覆モデル
    - 施設配置モデル
      - 劣モジュラ最適化問題に帰着できる
      - 文の類似度を計算する必要がある
      - 原論文では単語の重複をスコアとしている
        - ROUGEみたいな
        - ２０２２年現在では[文の分散表現を求める]({{<ref "post/20220302embedding-matome/index.md">}})こともできるのでそこはケースバイケースで特徴量を選択する
- LexRank
  - 文間の類似度からグラフ関係を計算して、重要な文をランキングする
  - 文字数の指定はできない
  - Sentence Transformersのサイトに[実装例](https://sbert.net/examples/applications/text-summarization/README.html)がある
    - 日本語に適用するには多少の修正が必要になる
  - 別に文の間の類似度が出せるならSBERTでなくてもいい
    - ROUGE, [USE]({{<ref "post/universal-sentence-encoder/index.md">}})など

### サービス
- [イライザダイジェスト](https://www.digest.elyza.ai/)
  - ３文に要約
  - 割と内容を理解した出力をする印象
  - 生成型特有のゆらぎが見られる
    - 不自然な箇所に句読点など
- [タンテキ](https://ai-tanteki.com/sanbun/)
  - ３文に要約
  - 抜粋型か？

## 参考文献
- [文書要約のための数理的手法](http://www.orsj.or.jp/archive2/or62-11/or62_11_711.pdf)