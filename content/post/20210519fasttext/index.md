---
title: "fasttext はなぜ速いのか？"
description: ""
date: "2021-05-19T02:10:01+09:00"
thumbnail: "/img/automobile-3075396_1920.jpg"
tags: [自然言語処理,分散表現]
---
## fasttextの特徴
- 目的関数の改善
  - ネガティブサンプルの考慮
  - こちらは学習時間に影響しないはず
- 最適化手法の変更
  - 確率的最適化の採用
  - 学習時間に影響するとしたらこちら
- 実装がC言語
  - これが一番効いているのではないか？

## pytorch で実装したらword2vecと大差ないのでは？
学習するデータ量にもよるだろうが、
トイプログラムでは有意な差は計測できそうにない。

## 論文に書かれていない実装面での工夫が隠れている？
- 実装面での工夫が存在している？
  - それを論文に記述していないのは卑怯じゃないか？
  - 実装で高速にしました、というのは不誠実な気がする

## 論文を読んだだけではどこがfastなのかが分からない
- なにをもって高速にしたのだろうね？

## 分散表現の仕組みについて学ぶ
- 単語の意味を学習する分散表現について、実際にプログラムを実行しながら仕組みを理解するために[Googlecolaboratory と pythonで学ぶ初めての 自然言語処理入門](https://subcul-science.booth.pm/items/1562211)をおすすめします。
  - 分散表現の学習のイメージをつかめるとBERT系で何をどのように学習しているのかについても理解が深まります。
- また[fasttext の説明してみました](https://subcul-science.booth.pm/items/3152477)もオススメします。