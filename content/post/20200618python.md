---
title: 'python を用いた自然言語処理の環境を整える'
date: 2020-06-18T07:34:00.004+09:00
draft: false
aliases: [ "/2020/06/python.html" ]
tags : [技術系,python,自然言語処理,技術,環境構築]
---

[![](https://1.bp.blogspot.com/-Hfn3KpibOuY/Xurepq-smKI/AAAAAAAAg70/y4-SSiS1Mc4gMmbTywgn9jCzZboq6XAJACK4BGAsYHg/s320/74C0A734-70D2-4846-A316-312BA6691D8B.jpeg)](https://1.bp.blogspot.com/-Hfn3KpibOuY/Xurepq-smKI/AAAAAAAAg70/y4-SSiS1Mc4gMmbTywgn9jCzZboq6XAJACK4BGAsYHg/s1920/74C0A734-70D2-4846-A316-312BA6691D8B.jpeg)

この記事はコマンドラインをある程度利用できる方に向けて書いています。

コマンドラインがなにか分からないけど、pythonを使いたい方はGoogle Colaboratory というサービスの利用を検討してください。

## **実行環境の整備**
- まずはpythonの実行環境を整えます。
- 今回はMac+コマンドラインの利用を前提としています。
- 詳細は以下のリンクを参考にします。
  - [Macでpyenvを利用したpythonの環境構築の方法]({{<ref "/post/20200616mac-python.md">}})

## **形態素解析 **

- 次に前処理を行います。
- 日本語の場合は形態素解析を用いたトークナイズが必須となります。
- python 上で形態素解析を行えるライブラリとしてjanomeやginzaがあります。
- どちらもpipコマンドを実行することで簡単にインストールできます。
- 詳細は各ホームページを参照してください。
  - [Janome v0.3 documentation (ja)](https://mocobeta.github.io/janome/)
  - [GiNZA - Japanese NLP Library](https://megagonlabs.github.io/ginza/)

## **文や単語の特徴量**

- 文はそのままでは計算機は単語や文章の意味を扱うことができません。
- そこでいくつかの方法で単語の意味を表現しようという試みがあります。

## **単語の出現頻度による特徴量**

- 単語の出現頻度を特徴量として扱うものとして、TF-IDFがあります。
- TF-IDF の詳細や利用方法については工事中です。
- とりあえずは以下を参照してください。[scikit-learn で tf-idf を求める](https://tex2e.github.io/blog/python/tf-idf)

## **分散表現を用いる方法**
- 単語の意味を分散表現(ベクトル)を用いて表そうという方法があります。
- すでにライブラリが整備されているのでそれらを利用するのが懸命です。
- 各種ライブラリの手順については以下のリンクを参考にしてください。
  - [Fasttext で文書分類問題までやったった]({{<ref "/post/20200613fasttext.md">}})
  - [文書分類問題を解くモデルを提供するNeuralClassifier の使い方メモ]({{<ref "/post/neuralclassifier.md">}})
  - [日本語Wikipediaで学習済みのBERTが公開されているので使い方メモ]({{<ref "/post/wikipediabert.md">}})

## 実際のアルゴリズムの動作に興味がある人は以下を参照してください。
- [Google colaboratory を使ってWord2Vec の仕組みからモデルの学習まで](https://subcul-science.booth.pm/items/1562211)
